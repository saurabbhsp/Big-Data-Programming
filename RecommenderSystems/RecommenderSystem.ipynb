{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system\n",
    "## Dataset - MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.104:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir(\"/home/saurabh/sparkcheckpointDir/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession.builder.appName(\"RecommenderSystems\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System - 1 \n",
    "## Implemented from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sc.textFile(\"/home/saurabh/ml-1m/ratings.dat\").map(\n",
    "                        lambda line: line.split(\"::\")).map(lambda x: (int(x[0]), (int(x[1]), float(x[2]) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (1193, 5.0)), (1, (661, 3.0)), (1, (914, 3.0))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([7, 3], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ratings_partitions = train.partitionBy(2).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, (1357, 5.0)), (2, (3068, 4.0)), (2, (1537, 4.0))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_partitions.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 6040\n",
    "n_items = 3952\n",
    "latent_variables = 100\n",
    "\n",
    "global_bias = np.array([2.5])\n",
    "user_latent = np.random.uniform(size = (n_users + 1, latent_variables))\n",
    "user_bias = np.random.uniform(size=(n_users + 1))\n",
    "\n",
    "item_latent = np.random.uniform(size = (n_items + 1, latent_variables))\n",
    "item_bias = np.random.uniform(size = (n_items + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core algorithm\n",
    "The following code is a varient of matrix factorization for recommender systems. In addition to user and item latent variables this algorithm also uses user and item bias and global bias.\n",
    "\n",
    "### Solving cold start problem\n",
    "\n",
    "    -- The user bias allows to rate for new item that was not seen in the training data\n",
    "    -- The item bias allows to rate for new user that was not seen in the training data\n",
    "    -- Global bias allows to provide rating for both new user and new item\n",
    "### Learning parameters\n",
    "\n",
    "    -- SGD is used to learn user_bias, user_latent features, item_bias and item_latent features.\n",
    "    -- Global bias is not learned. It is usually calculated as average of all the ratings.\n",
    "### Regualrization\n",
    "This model also performs regularization subject to the regularization parameter.\n",
    "\n",
    "### Prediction\n",
    "The prediction is globalBias + userBias + itemBias + matrixProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localGradients(data_iterator, user_latent = user_latent, user_bias = user_bias,\n",
    "                   item_latent = item_latent, item_bias = item_bias,\n",
    "                   global_bias = global_bias, learning_rate = 1e-2, regularization = 1e-1):\n",
    "    \n",
    "    \"\"\"Put default values to zeros\"\"\"\n",
    "    _user_latent = np.zeros_like(user_latent)\n",
    "    _item_latent = np.zeros_like(item_latent)\n",
    "    _user_bias = np.zeros_like(user_bias)\n",
    "    _item_bias = np.zeros_like(item_bias)\n",
    "    \n",
    "    for user, item_rating in data_iterator:\n",
    "        item = item_rating[0]\n",
    "        actual = item_rating[1]\n",
    "        \n",
    "        \"\"\"The predicion is global_bias + user_bias + item_bias + latentFactorsDotProduct\"\"\"\n",
    "        \n",
    "        prediction = global_bias + user_bias[user] + item_bias[item] + np.dot(user_latent[user],\n",
    "                                                                                   item_latent[item].T)\n",
    "        user_latent[user] = user_latent[user] + learning_rate * \\\n",
    "                            (((actual - prediction) * item_latent[item]) \\\n",
    "                            - regularization * (user_latent[user]))\n",
    "        \n",
    "        item_latent[item] = item_latent[item] + learning_rate * \\\n",
    "                            (((actual - prediction) * user_latent[user]) \\\n",
    "                            - regularization * (item_latent[item]))\n",
    "        \n",
    "        user_bias[user] = user_bias[user] + learning_rate * \\\n",
    "                          ((actual - prediction) \\\n",
    "                          - regularization * user_bias[user])\n",
    "        \n",
    "        item_bias[item] = item_bias[item] + learning_rate * \\\n",
    "                          ((actual - prediction) \\\n",
    "                          - regularization * item_bias[item])\n",
    "        \n",
    "        \"\"\"Keep weights of all non learned latent features as 0\"\"\"\n",
    "        _item_bias[item] = np.array(item_bias[item])\n",
    "        _item_latent[item] = np.array(item_latent[item])\n",
    "        _user_bias[user] = np.array(user_bias[user])\n",
    "        _user_latent[user] = np.array(user_latent[user])\n",
    "        \n",
    "    return (_user_latent, _item_latent, _user_bias, _item_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE Calculation\n",
    "Following code will calculate RMSE for the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(data_iterator, user_latent = user_latent, user_bias = user_bias,\n",
    "        item_latent = item_latent, item_bias = item_bias,\n",
    "        global_bias = global_bias):\n",
    "    error = []\n",
    "    \n",
    "    for user, item_rating in data_iterator:\n",
    "        item = item_rating[0]\n",
    "        _actual = item_rating[1]\n",
    "        \n",
    "        \"\"\"The predicion is global_bias + user_bias + item_bias + latentFactorsDotProduct\"\"\"\n",
    "        \n",
    "        _prediction = global_bias + user_bias[user] + item_bias[item] + np.dot(user_latent[user],\n",
    "                                                                                   item_latent[item].T)\n",
    "        error.append(_prediction - _actual)\n",
    "    return [math.sqrt(np.mean(np.array(error) ** 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed matrix factorization\n",
    "\n",
    "    -- The above code will work in distributed settings. (Across the partitions)\n",
    "    -- The average should be calculated for only non zero terms.\n",
    "Following method allows to calculate average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_average(x):\n",
    "    sum_vector = np.zeros_like(x[0])\n",
    "    cummulative = np.zeros(len(x[0]))\n",
    "    for item in x:\n",
    "        for index, data in enumerate(item):\n",
    "            if np.sum(data) > 0:\n",
    "                cummulative[index] = cummulative[index] + 1\n",
    "                sum_vector[index] = sum_vector[index] + data\n",
    "    for index, data in enumerate(sum_vector):\n",
    "        if cummulative[index] > 0:\n",
    "            sum_vector[index] = data/cummulative[index]\n",
    "    return sum_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data, index, n_partitions):\n",
    "    array = []\n",
    "    while index < n_partitions * 4:\n",
    "        array.append(data[index])\n",
    "        index = index + 4\n",
    "    return non_zero_average(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce method is not used\n",
    "The following code does not use a reduce method. This is because the output of the map partitions is an array and not a tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE-25.058494210066556\n",
      "Test RMSE-25.061564781800932\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-1.3912778700616217\n",
      "Test RMSE-1.4836147226254353\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.9718266521290175\n",
      "Test RMSE-1.1243123750950648\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.9052402275926952\n",
      "Test RMSE-1.0567820449881378\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.8827609682704174\n",
      "Test RMSE-1.0248377990720927\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.8733300245326387\n",
      "Test RMSE-1.0052995680618988\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.8693399681715661\n",
      "Test RMSE-0.9918792889263015\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.867650549118595\n",
      "Test RMSE-0.981681846194268\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.8673571371066514\n",
      "Test RMSE-0.9737957586843251\n",
      "\n",
      "\n",
      "\n",
      "Train RMSE-0.8671835985965081\n",
      "Test RMSE-0.9673039346124579\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainRMSEList = []\n",
    "testRMSEList = []\n",
    "partition_count =  ratings_partitions.getNumPartitions()\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    \n",
    "    \"\"\"Check performance\"\"\"\n",
    "    rmse = ratings_partitions.mapPartitions(lambda x:RMSE(x, user_latent=user_latent,\n",
    "                                                          user_bias=user_bias,\n",
    "                                                          item_latent=item_latent,\n",
    "                                                          item_bias=item_bias,\n",
    "                                                         global_bias=global_bias))\n",
    "    rmse = np.average(rmse.coalesce(1).collect())\n",
    "    print(\"Train RMSE-\"+str(rmse))\n",
    "    trainRMSEList.append(rmse)\n",
    "    \n",
    "    rmse = test.mapPartitions(lambda x:RMSE(x, user_latent=user_latent,\n",
    "                                            user_bias=user_bias,\n",
    "                                            item_latent=item_latent, item_bias=item_bias,\n",
    "                                            global_bias=global_bias))\n",
    "    rmse = np.average(rmse.coalesce(1).collect())\n",
    "    print(\"Test RMSE-\"+str(rmse))\n",
    "    testRMSEList.append(rmse)\n",
    "    \n",
    "    \"\"\"Train model\"\"\"\n",
    "    tmp = ratings_partitions.mapPartitions(lambda x:localGradients(x, user_latent=user_latent,\n",
    "                                                                     user_bias=user_bias,\n",
    "                                                                     item_latent=item_latent,\n",
    "                                                                     item_bias=item_bias,\n",
    "                                                                     global_bias=global_bias))\n",
    "    tmp = tmp.coalesce(1).collect()\n",
    "    user_latent = average(tmp, 0, partition_count)\n",
    "    item_latent = average(tmp, 1, partition_count)\n",
    "    user_bias = average(tmp, 2, partition_count)\n",
    "    item_bias = average(tmp, 3, partition_count)\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE-0.8671977557957844\n",
      "Test RMSE-0.9619186176332075\n"
     ]
    }
   ],
   "source": [
    "rmse = ratings_partitions.mapPartitions(lambda x:RMSE(x, user_latent=user_latent,\n",
    "                                                      user_bias=user_bias,\n",
    "                                                      item_latent=item_latent, item_bias=item_bias,\n",
    "                                                       global_bias=global_bias))\n",
    "rmse = np.average(rmse.coalesce(1).collect())\n",
    "print(\"Train RMSE-\"+str(rmse))\n",
    "trainRMSEList.append(rmse)\n",
    "    \n",
    "rmse = test.mapPartitions(lambda x:RMSE(x, user_latent=user_latent,\n",
    "                                        user_bias=user_bias,\n",
    "                                        item_latent=item_latent, item_bias=item_bias,\n",
    "                                        global_bias=global_bias))\n",
    "\n",
    "rmse = np.average(rmse.coalesce(1).collect())\n",
    "print(\"Test RMSE-\"+str(rmse))\n",
    "testRMSEList.append(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainRMSEList, label = \"Train RMSE\")\n",
    "plt.plot(testRMSEList, label = \"Test RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performance on train set is 0.86 and test set is 0.96. We can say that the algorithm slightly overfits to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System - 2 \n",
    "## Implemented using MLLib\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1193, 5.0), (1, 661, 3.0), (1, 914, 3.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = sc.textFile(\"/home/saurabh/ml-1m/ratings.dat\").map(\n",
    "                        lambda token: token.split(\"::\")).map(lambda token: (\n",
    "                                                            int(token[0]), int(token[1]), float(token[2])))\n",
    "movies = sc.textFile(\"/home/saurabh/ml-1m/movies.dat\").map(\n",
    "                        lambda token: token.split(\"::\")).map(lambda token: (token[0], token[1]))\n",
    "\n",
    "ratings.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([7, 3], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformRDD(rdd):\n",
    "    return rdd.map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_MLLib(actual, predictions):\n",
    "    joined_rdd = transformRDD(actual).join(predictions)\n",
    "    error = math.sqrt(joined_rdd.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for hyper parameter search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Following code is using CrossValidator. But performance is not good\"\"\"\n",
    "\n",
    "\n",
    "als = ALS(seed=0, implicitPrefs=True)\n",
    "pipeline = Pipeline(stages=[als])\n",
    "# paramGrid = ParamGridBuilder().addGrid(als.rank, [5, 10, 15, 20]).addGrid(als.alpha, [0.1, 0.2, 0.3]).build()\n",
    "paramGrid = ParamGridBuilder().addGrid(als.rank, [5]).addGrid(als.regParam, [0.1, 0.2, 0.3]).build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "model = crossval.fit(train)\n",
    "\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")\n",
    "evaluator.evaluate(model.transform(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-5 error 0.8790564334285227\n",
      "Rank-25 error 0.8753892226100661\n",
      "Rank-35 error 0.8751212570490433\n",
      "Rank-45 error 0.8756921670140858\n",
      "Rank-100 error 0.8755746255382981\n",
      "Error on test set is 0.8625036830611713\n"
     ]
    }
   ],
   "source": [
    "\"\"\"here rank is hyper parameter\"\"\"\n",
    "rankList = [5, 25, 35, 45, 100]\n",
    "leastError = None\n",
    "bestRank = None\n",
    "\n",
    "\n",
    "_train, _validation = train.randomSplit([7, 3], seed=0)\n",
    "for rank in rankList:\n",
    "    \"\"\"lambda_ is used for regularization\"\"\"\n",
    "    model = ALS.train(_train, rank, iterations=20, lambda_=0.1)\n",
    "    _validation_transformed = _validation.map(lambda p: (p[0], p[1]))\n",
    "    prediction = transformRDD(model.predictAll(_validation_transformed))\n",
    "    error = RMSE_MLLib(_validation, prediction)\n",
    "    print(\"Rank-\"+str(rank)+\" error \"+str(error))\n",
    "    if leastError is None or leastError > error:\n",
    "        leastError = error\n",
    "        bestRank = rank\n",
    "\n",
    "model = ALS.train(train, bestRank, iterations=20, lambda_=0.1)\n",
    "\n",
    "_test = test.map(lambda p: (p[0], p[1]))\n",
    "prediction = transformRDD(model.predictAll(_test))\n",
    "error = RMSE_MLLib(test, prediction)\n",
    "print(\"Error on test set is \"+str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "    -- Comparing the two implementations, spark's default implementation is much more optimized. \n",
    "    -- It also generates better results. Test set accuracy of 0.96 vs 0.86\n",
    "    -- When compared to existing approaches the accuracy is 0.857 for biased matrix factorization method which is very close to the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
